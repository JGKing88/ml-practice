{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "#add CIFAR10 data in the environment\n",
    "sys.path.append(cwd + '/../cifar10')\n",
    "\n",
    "#Numpy is linear algebra lbrary\n",
    "import numpy as np\n",
    "# Matplotlib is a visualizations library \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.features =16\n",
    "        \n",
    "        \n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(3, 6, 5), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2, 2), \n",
    "                                     nn.Conv2d(6, 16, 5),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2, 2),\n",
    "                                     nn.Flatten(),\n",
    "                                     nn.Linear(16 * 5 * 5, 120), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(120, self.features * 2),\n",
    "                                     nn.ReLU())\n",
    "\n",
    "        # decoder\n",
    "        self.decoder_linear = nn.Sequential(nn.Linear(in_features=self.features, out_features=120),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(in_features=120, out_features=16 * 5 * 5),\n",
    "                                            nn.ReLU())\n",
    "        self.decoder_conv = nn.Sequential(nn.ConvTranspose2d(16, 10, 8, padding=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.ConvTranspose2d(10, 6, 21, padding=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.ConvTranspose2d(6, 3, 5),\n",
    "                                          nn.Flatten(),\n",
    "                                         nn.Sigmoid())\n",
    "                                          \n",
    "                                     \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = self.encoder(x).view(-1, 2, self.features)\n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :]  # the first feature values as mean\n",
    "        log_var = x[:, 1, :]  # the other feature values as variance\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # decoding\n",
    "        x = self.decoder_linear(z)\n",
    "        x = x.view(-1, 16, 5, 5)\n",
    "        reconstruction = self.decoder_conv(x)\n",
    "        return reconstruction, mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "            \"\"\"\n",
    "            :param mu: mean from the encoder's latent space\n",
    "            :param log_var: log variance from the encoder's latent space\n",
    "            \"\"\"\n",
    "            std = torch.exp(0.5 * log_var)  # standard deviation\n",
    "            eps = torch.randn_like(std)  # generate sample of the same size\n",
    "            sample = mu + (eps * std)  # sampling as if coming from the input space\n",
    "            return sample\n",
    "\n",
    "def final_loss(bce_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the\n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(model,training_data):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(training_data, 0):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(-1, 3, 32, 32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            reconstruction, mu, logvar = model(inputs)\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            bce_loss = criterion(reconstruction, inputs)\n",
    "            loss = final_loss(bce_loss, mu, logvar)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    print('Finished Training')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = VAE()\n",
    "train(model, trainloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,  2000] loss: -307884.120\n",
      "[1,  4000] loss: -364185.945\n",
      "[1,  6000] loss: -391470.040\n",
      "[1,  8000] loss: -404930.131\n",
      "[1, 10000] loss: -408856.913\n",
      "[1, 12000] loss: -411827.272\n",
      "Finished Training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.rand(16*5*5)\n",
    "x = x.view(-1, 16, 5, 5)\n",
    "print(x.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}